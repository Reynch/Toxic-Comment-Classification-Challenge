{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Toxcicty Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:58.655242Z",
     "start_time": "2023-11-14T04:40:57.921954Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.221721Z",
     "start_time": "2023-11-14T04:40:58.656270Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('data/train.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.236925Z",
     "start_time": "2023-11-14T04:40:59.222724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.268244Z",
     "start_time": "2023-11-14T04:40:59.238724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159571 entries, 0000997932d777bf to fff46fc426af1f9a\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   comment_text   159571 non-null  object\n",
      " 1   toxic          159571 non-null  int64 \n",
      " 2   severe_toxic   159571 non-null  int64 \n",
      " 3   obscene        159571 non-null  int64 \n",
      " 4   threat         159571 non-null  int64 \n",
      " 5   insult         159571 non-null  int64 \n",
      " 6   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.362515Z",
     "start_time": "2023-11-14T04:40:59.269247Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.378716Z",
     "start_time": "2023-11-14T04:40:59.363570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
       "3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
       "4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  \n",
       "1             -1  \n",
       "2             -1  \n",
       "3             -1  \n",
       "4             -1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.394199Z",
     "start_time": "2023-11-14T04:40:59.379570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for improving parts of speech information\n",
    "\n",
    "### get_wordnet_pos was taken from Lecture 51-nlp_modeling.ipynb \n",
    "### link to the lecture: https://github.com/dvdhartsman/NTL-DS-080723/blob/main/4phase/51-nlp_modeling.ipynb\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.410124Z",
     "start_time": "2023-11-14T04:40:59.395201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for handling the transformation of data\n",
    "\n",
    "### preprocess taken from nlp-sentiment-analysis\n",
    "### link to the project: https://github.com/dvdhartsman/NLP-Sentiment-Analysis/blob/main/Text_Classification_Final_Notebook.ipynb\n",
    "\n",
    "def preprocess(comment):\n",
    "    \"\"\"\n",
    "    This is a function that is intended to handle all of the tokenization, lemmatization, and other\n",
    "    preprocessing for our tweet data. It will make use of objects from other libraries, and will return\n",
    "    a complete list of tokens that are ready to be vectorized into numerical data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list of stopwords to be removed from our tokenized word list\n",
    "    stops = stopwords.words(\"english\")\n",
    "    # Add punctuation to the list of stopwords\n",
    "    stops += string.punctuation\n",
    "    # Providing a regex pattern for the tokenizer to handle\n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    # Instantiating a tokenizer\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    # Creating a list of raw tokens\n",
    "    raw_tokens = tokenizer.tokenize(comment)\n",
    "    # Using a comprehension to lower case every token\n",
    "    lower_tokens = [i.lower() for i in raw_tokens]\n",
    "    # Remove the stopwords from the list of tokens\n",
    "    stopped_words = [i for i in lower_tokens if i not in stops]\n",
    "    \n",
    "    # Adding parts of speech to prepare for Lemmatization\n",
    "    \n",
    "    # This is the initial method to get parts of speech\n",
    "    stopped_words = pos_tag(stopped_words)\n",
    "    \n",
    "    # Get_wordnet_pos() is the function to modify the pos definitions/assignments, creates tuples of (<word>, <pos>)\n",
    "    stopped_words = [(word[0], get_wordnet_pos(word[1])) for word in stopped_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    \n",
    "    # This corrects the parts of speech and maximizes the usefulness of the lemmatization!!!!!\n",
    "    document = [lemmatizer.lemmatize(word[0], word[1]) for word in stopped_words]\n",
    "    \n",
    "    # Re-join the list of cleaned tokens\n",
    "    cleaned_doc = \" \".join(document)\n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:40:59.425261Z",
     "start_time": "2023-11-14T04:40:59.410124Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_train.comment_text\n",
    "y = df_train[['toxic', 'severe_toxic', 'obscene', 'threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T17:31:49.020327Z",
     "start_time": "2023-11-03T17:31:48.979686Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify=['toxic', 'severe_toxic','identity_hate'])\n",
    "y_toxic_train = df_train.toxic\n",
    "y_severe_toxic_train = df_train.severe_toxic\n",
    "y_obscene_train = df_train.obscene\n",
    "y_threat_train = df_train.threat\n",
    "y_insult_train = df_train['identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:41:00.179161Z",
     "start_time": "2023-11-14T04:40:59.427254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"d'aww match background colour i'm seemingly stuck thanks talk january utc\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:41:55.703803Z",
     "start_time": "2023-11-14T07:38:28.916292Z"
    }
   },
   "outputs": [],
   "source": [
    "X_clean = X.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:41:55.843798Z",
     "start_time": "2023-11-14T07:41:55.704806Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "tf_vec = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:42:16.320497Z",
     "start_time": "2023-11-14T07:41:55.845015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=10000, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.fit(X_clean)\n",
    "tf_vec.fit(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:42:24.734078Z",
     "start_time": "2023-11-14T07:42:16.322214Z"
    }
   },
   "outputs": [],
   "source": [
    "X_count = count_vec.transform(X_clean)\n",
    "X_tfidf = tf_vec.transform(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:42:24.749385Z",
     "start_time": "2023-11-14T07:42:24.735110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4444977 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:42:24.764328Z",
     "start_time": "2023-11-14T07:42:24.751894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4444977 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:42:24.826571Z",
     "start_time": "2023-11-14T07:42:24.765317Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_cv, X_test_cv, y_train, y_test = train_test_split(X_count,y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T07:42:24.873166Z",
     "start_time": "2023-11-14T07:42:24.827604Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train, y_test = train_test_split(X_tfidf,y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:41:01.305452Z",
     "start_time": "2023-11-14T04:41:01.305452Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_train.apply(preprocess)\n",
    "\n",
    "\"\"\"id\n",
    "0000997932d777bf    explanation edits make username hardcore metal...\n",
    "000103f0d9cfb60f    d'aww match background colour i'm seemingly st...\n",
    "000113f07ec002fd    hey man i'm really try edit war guy constantly...\n",
    "0001b41b1c6bb37e    can't make real suggestion improvement wonder ...\n",
    "0001d958c54c6e35                 sir hero chance remember page that's\n",
    "                                          ...                        \n",
    "ffe987279560d7ff    second time ask view completely contradict cov...\n",
    "ffea4adeee384e90                 ashamed horrible thing put talk page\n",
    "ffee36eab5c267c9    spitzer umm there actual article prostitution ...\n",
    "fff125370e4aaaf3    look like actually put speedy first version de...\n",
    "fff46fc426af1f9a    really think understand come idea bad right aw...\n",
    "Name: comment_text, Length: 159571, dtype: object\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T04:41:01.306452Z",
     "start_time": "2023-11-14T04:41:01.306452Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiOutput():\n",
    "    # a class to more easily test, interpret and store different classifiers for a multioutput dataset\n",
    "    model_list = []\n",
    "    model_df = pd.DataFrame(columns = ['Classifier', 'train_accuracy','train_prec','train_recall','train_f1',\n",
    "                                      'test_accuracy','test_prec','test_recall','test_f1'])\n",
    "    \n",
    "    def __init__(self, name, clf, X_train, X_test, y_train, y_test):\n",
    "        self.name = name\n",
    "        self.clf = classifier\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        # Measuring model\n",
    "        self.train_results = cross_validate(self.model, self.X_train, self.y_train, scoring=[\n",
    "            'precision', 'accuracy', 'recall', 'f1', 'neg_log_loss'], n_jobs=4, verbose=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Dummy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:30.931823Z",
     "start_time": "2023-11-14T08:04:30.919464Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:31.270823Z",
     "start_time": "2023-11-14T08:04:31.238975Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_clf = MultiOutputClassifier(dummy).fit(X_train_cv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:31.502865Z",
     "start_time": "2023-11-14T08:04:31.461384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898343889436655"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, dummy_clf.predict(X_train_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:31.658734Z",
     "start_time": "2023-11-14T08:04:31.639041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982528263103803"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dummy_clf.predict(X_test_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:31.798856Z",
     "start_time": "2023-11-14T08:04:31.789674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c912439967ba8a35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b312f612d3394d5b</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813c210bf7f27377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c231999bc75dcd9e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d60a1de68cf593c1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811ed72c51830f42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2acc7c7d0386401f</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1f95b89050a9ee4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32e8bdecfe1d66f0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c6c5e4228fb6ba8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "id                                                                           \n",
       "c912439967ba8a35      0             0        0       0       0              0\n",
       "b312f612d3394d5b      0             0        0       0       0              0\n",
       "813c210bf7f27377      0             0        0       0       0              0\n",
       "c231999bc75dcd9e      0             0        0       0       0              0\n",
       "d60a1de68cf593c1      0             0        0       0       0              0\n",
       "...                 ...           ...      ...     ...     ...            ...\n",
       "811ed72c51830f42      0             0        0       0       0              0\n",
       "2acc7c7d0386401f      0             0        0       0       0              0\n",
       "c1f95b89050a9ee4      1             0        0       0       0              0\n",
       "32e8bdecfe1d66f0      0             0        0       0       0              0\n",
       "8c6c5e4228fb6ba8      0             0        0       0       0              0\n",
       "\n",
       "[119678 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T05:36:59.685247Z",
     "start_time": "2023-11-07T05:36:59.663622Z"
    }
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:38.905418Z",
     "start_time": "2023-11-14T08:04:32.166018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rchag\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rchag\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rchag\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rchag\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rchag\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rchag\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg_clf = MultiOutputClassifier(LogisticRegression()).fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:39.015991Z",
     "start_time": "2023-11-14T08:04:38.906428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319590902254382"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, logreg_clf.predict(X_train_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:39.063326Z",
     "start_time": "2023-11-14T08:04:39.016994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9147970821948713"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, logreg_clf.predict(X_test_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:39.095429Z",
     "start_time": "2023-11-14T08:04:39.064319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_clf.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:43.487628Z",
     "start_time": "2023-11-14T08:04:39.096428Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg_clf_tf = MultiOutputClassifier(LogisticRegression()).fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:43.566196Z",
     "start_time": "2023-11-14T08:04:43.488684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9246227376794398"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, logreg_clf_tf.predict(X_train_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:04:43.597720Z",
     "start_time": "2023-11-14T08:04:43.567200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9191336826009575"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, logreg_clf_tf.predict(X_test_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:14:48.881820Z",
     "start_time": "2023-11-14T08:14:20.858100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfclf = MultiOutputClassifier(RandomForestClassifier(n_jobs = -1, random_state=42, max_depth=50, verbose = 1)).fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:14:49.379599Z",
     "start_time": "2023-11-14T08:14:48.882824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9049958639360289"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rfclf.predict(X_test_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:17.581150Z",
     "start_time": "2023-11-14T08:15:48.857148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "rfclf_tf = MultiOutputClassifier(RandomForestClassifier(n_jobs = -1, random_state=42, max_depth=50, verbose = 1)).fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:23.241211Z",
     "start_time": "2023-11-14T08:16:22.686973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9052716015341037"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rfclf_tf.predict(X_test_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T21:53:33.856710Z",
     "start_time": "2023-11-07T21:53:33.842223Z"
    }
   },
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:48.240223Z",
     "start_time": "2023-11-14T08:16:48.144722Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_cv = MultiOutputClassifier(MultinomialNB()).fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:48.827472Z",
     "start_time": "2023-11-14T08:16:48.776454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033915724563206"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, mnb_cv.predict(X_test_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:56.610275Z",
     "start_time": "2023-11-14T08:16:56.488950Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_tf = MultiOutputClassifier(MultinomialNB()).fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:57.165418Z",
     "start_time": "2023-11-14T08:16:57.119757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8979018875491941"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, mnb_tf.predict(X_test_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:16:58.002199Z",
     "start_time": "2023-11-14T08:16:57.960564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_tf.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T05:25:11.145996Z",
     "start_time": "2023-11-08T05:25:11.128512Z"
    }
   },
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:15:52.595869Z",
     "start_time": "2023-11-14T10:15:52.583354Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:17:03.146691Z",
     "start_time": "2023-11-14T08:17:02.873395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:17:11.516464Z",
     "start_time": "2023-11-14T08:17:11.496860Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs, dropout = None, layer_amnt = 1):    \n",
    "    model = Sequential()\n",
    "    if dropout != None:\n",
    "        model.add(layers.Dropout(0.2, input_shape = (n_inputs,)))\n",
    "    else:\n",
    "        model.add(layers.Dense(128, input_dim = n_inputs, activation = 'relu'))\n",
    "    for i in range(layer_amnt):\n",
    "        model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dense(n_outputs, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:17:13.790575Z",
     "start_time": "2023-11-14T08:17:13.736926Z"
    }
   },
   "outputs": [],
   "source": [
    "nn1 = get_model(10000, y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:17:17.362521Z",
     "start_time": "2023-11-14T08:17:14.688537Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_cv_df = pd.DataFrame(X_train_cv.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:17:19.096748Z",
     "start_time": "2023-11-14T08:17:19.080727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  9990  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   9991  9992  9993  9994  9995  9996  9997  9998  9999  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:45.828337Z",
     "start_time": "2023-11-14T08:17:36.639208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3740/3740 [==============================] - 14s 4ms/step - loss: 0.0780\n",
      "Epoch 2/10\n",
      "3740/3740 [==============================] - 14s 4ms/step - loss: 0.0452\n",
      "Epoch 3/10\n",
      "3740/3740 [==============================] - 13s 4ms/step - loss: 0.0325\n",
      "Epoch 4/10\n",
      "3740/3740 [==============================] - 12s 3ms/step - loss: 0.0238\n",
      "Epoch 5/10\n",
      "3740/3740 [==============================] - 12s 3ms/step - loss: 0.0177\n",
      "Epoch 6/10\n",
      "3740/3740 [==============================] - 12s 3ms/step - loss: 0.0134\n",
      "Epoch 7/10\n",
      "3740/3740 [==============================] - 13s 3ms/step - loss: 0.0110\n",
      "Epoch 8/10\n",
      "3740/3740 [==============================] - 13s 3ms/step - loss: 0.0094\n",
      "Epoch 9/10\n",
      "3740/3740 [==============================] - 12s 3ms/step - loss: 0.0076\n",
      "Epoch 10/10\n",
      "3740/3740 [==============================] - 12s 3ms/step - loss: 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27313151cd0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.fit(X_train_cv_df, y_train, verbose = 1, epochs = 10, workers = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:46.531909Z",
     "start_time": "2023-11-14T08:19:45.830846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6895937e-13, 5.0766926e-31, 9.6251119e-19, 1.2269380e-14,\n",
       "        5.5974568e-16, 5.8830839e-08],\n",
       "       [2.7840697e-16, 3.2264358e-32, 7.9704894e-20, 6.1808552e-23,\n",
       "        3.8825261e-25, 5.8606067e-23],\n",
       "       [5.7309342e-07, 5.6108182e-16, 2.2887505e-07, 1.7737964e-11,\n",
       "        1.0667616e-06, 1.1299388e-08],\n",
       "       ...,\n",
       "       [7.4024206e-32, 0.0000000e+00, 8.6934771e-26, 1.4145657e-34,\n",
       "        0.0000000e+00, 3.1012409e-36],\n",
       "       [2.8984443e-16, 0.0000000e+00, 9.7382556e-30, 1.1496288e-29,\n",
       "        1.2732751e-30, 1.5187697e-14],\n",
       "       [1.9811688e-08, 6.9785545e-20, 3.4147372e-06, 6.0970320e-19,\n",
       "        2.9635132e-09, 5.5500569e-11]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:46.547107Z",
     "start_time": "2023-11-14T08:19:46.532909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.7840697e-16 3.2264358e-32 7.9704894e-20 6.1808318e-23 3.8825113e-25\n",
      "  5.8606288e-23]]\n"
     ]
    }
   ],
   "source": [
    "print(nn1.predict(X_test_cv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:47.076697Z",
     "start_time": "2023-11-14T08:19:46.548616Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_cv = nn1.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:47.092711Z",
     "start_time": "2023-11-14T08:19:47.077706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6895937e-13, 5.0766926e-31, 9.6251119e-19, 1.2269380e-14,\n",
       "        5.5974568e-16, 5.8830839e-08],\n",
       "       [2.7840697e-16, 3.2264358e-32, 7.9704894e-20, 6.1808552e-23,\n",
       "        3.8825261e-25, 5.8606067e-23],\n",
       "       [5.7309342e-07, 5.6108182e-16, 2.2887505e-07, 1.7737964e-11,\n",
       "        1.0667616e-06, 1.1299388e-08],\n",
       "       ...,\n",
       "       [7.4024206e-32, 0.0000000e+00, 8.6934771e-26, 1.4145657e-34,\n",
       "        0.0000000e+00, 3.1012409e-36],\n",
       "       [2.8984443e-16, 0.0000000e+00, 9.7382556e-30, 1.1496288e-29,\n",
       "        1.2732751e-30, 1.5187697e-14],\n",
       "       [1.9811688e-08, 6.9785545e-20, 3.4147372e-06, 6.0970320e-19,\n",
       "        2.9635132e-09, 5.5500569e-11]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:47.108060Z",
     "start_time": "2023-11-14T08:19:47.093712Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_cv = yhat_cv.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:47.123079Z",
     "start_time": "2023-11-14T08:19:47.109564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_cv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:47.153481Z",
     "start_time": "2023-11-14T08:19:47.124071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9059734790564761"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:48.746543Z",
     "start_time": "2023-11-14T08:19:47.154481Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_train_cv = nn1.predict(X_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:48.761573Z",
     "start_time": "2023-11-14T08:19:48.748553Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_train_cv = yhat_train_cv.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:48.809186Z",
     "start_time": "2023-11-14T08:19:48.763572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9926970704724344"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, yhat_train_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:48.840412Z",
     "start_time": "2023-11-14T08:19:48.810186Z"
    }
   },
   "outputs": [],
   "source": [
    "nn2 = get_model(300, y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:48.855793Z",
     "start_time": "2023-11-14T08:19:48.841435Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_cv_300 = X_train_cv_df.iloc[:,0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:19:48.871407Z",
     "start_time": "2023-11-14T08:19:48.856855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  290  291  292  293  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    1   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   294  295  296  297  298  299  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv_300.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:20:09.738040Z",
     "start_time": "2023-11-14T08:19:48.872378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3740/3740 [==============================] - 2s 556us/step - loss: 0.1434\n",
      "Epoch 2/10\n",
      "3740/3740 [==============================] - 2s 578us/step - loss: 0.1355\n",
      "Epoch 3/10\n",
      "3740/3740 [==============================] - 2s 576us/step - loss: 0.1348\n",
      "Epoch 4/10\n",
      "3740/3740 [==============================] - 2s 555us/step - loss: 0.1343\n",
      "Epoch 5/10\n",
      "3740/3740 [==============================] - 2s 539us/step - loss: 0.1339\n",
      "Epoch 6/10\n",
      "3740/3740 [==============================] - 2s 560us/step - loss: 0.1335\n",
      "Epoch 7/10\n",
      "3740/3740 [==============================] - 2s 538us/step - loss: 0.1331\n",
      "Epoch 8/10\n",
      "3740/3740 [==============================] - 2s 526us/step - loss: 0.1327\n",
      "Epoch 9/10\n",
      "3740/3740 [==============================] - 2s 527us/step - loss: 0.1326\n",
      "Epoch 10/10\n",
      "3740/3740 [==============================] - 2s 530us/step - loss: 0.1319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273200609a0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2.fit(X_train_cv_300, y_train, verbose = 1, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:20:10.660522Z",
     "start_time": "2023-11-14T08:20:09.739043Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_train_cv_2 = nn2.predict(X_train_cv_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:20:10.676605Z",
     "start_time": "2023-11-14T08:20:10.661516Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_train_cv_2 = yhat_train_cv_2.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T08:20:10.707664Z",
     "start_time": "2023-11-14T08:20:10.677597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8991794648974749"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, yhat_train_cv_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:16:35.315055Z",
     "start_time": "2023-11-14T10:16:35.295505Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs, dropout = None, layer_amnt = 1):    \n",
    "    model = Sequential()\n",
    "    if dropout != None:\n",
    "        model.add(layers.Dropout(0.2, input_shape = (n_inputs,)))\n",
    "    else:\n",
    "        model.add(layers.Dense(128, input_dim = n_inputs, activation = 'relu'))\n",
    "    for i in range(layer_amnt):\n",
    "        model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dense(n_outputs, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:16:35.468297Z",
     "start_time": "2023-11-14T10:16:35.430608Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nndrop = get_model(10000, 6, dropout = True, layer_amnt = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:20:06.976823Z",
     "start_time": "2023-11-14T10:17:20.759832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3740/3740 [==============================] - 19s 5ms/step - loss: 0.0830\n",
      "Epoch 2/10\n",
      "3740/3740 [==============================] - 17s 5ms/step - loss: 0.0578\n",
      "Epoch 3/10\n",
      "3740/3740 [==============================] - 16s 4ms/step - loss: 0.0503\n",
      "Epoch 4/10\n",
      "3740/3740 [==============================] - 15s 4ms/step - loss: 0.0443\n",
      "Epoch 5/10\n",
      "3740/3740 [==============================] - 16s 4ms/step - loss: 0.0398\n",
      "Epoch 6/10\n",
      "3740/3740 [==============================] - 15s 4ms/step - loss: 0.0363\n",
      "Epoch 7/10\n",
      "3740/3740 [==============================] - 16s 4ms/step - loss: 0.0339\n",
      "Epoch 8/10\n",
      "3740/3740 [==============================] - 17s 4ms/step - loss: 0.0328\n",
      "Epoch 9/10\n",
      "3740/3740 [==============================] - 17s 4ms/step - loss: 0.0298\n",
      "Epoch 10/10\n",
      "3740/3740 [==============================] - 18s 5ms/step - loss: 0.0293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2739658c250>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndrop.fit(X_train_cv_df, y_train, verbose = 1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:22:17.491612Z",
     "start_time": "2023-11-14T10:22:16.926901Z"
    }
   },
   "outputs": [],
   "source": [
    "nndrop_test = nndrop.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:22:17.506749Z",
     "start_time": "2023-11-14T10:22:17.492149Z"
    }
   },
   "outputs": [],
   "source": [
    "nndrop_test = nndrop_test.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:22:20.386424Z",
     "start_time": "2023-11-14T10:22:20.368391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117890356704184"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, nndrop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:28:20.706506Z",
     "start_time": "2023-11-14T10:28:20.688495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_2 (Dropout)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,313,926\n",
      "Trainable params: 1,313,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nndrop.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NND 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:23:15.993852Z",
     "start_time": "2023-11-14T10:23:15.944477Z"
    }
   },
   "outputs": [],
   "source": [
    "nndrop2 = get_model(10000, 6, dropout = True, layer_amnt = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:26:15.422008Z",
     "start_time": "2023-11-14T10:23:23.711988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3740/3740 [==============================] - 17s 5ms/step - loss: 0.0812\n",
      "Epoch 2/10\n",
      "3740/3740 [==============================] - 17s 5ms/step - loss: 0.0590\n",
      "Epoch 3/10\n",
      "3740/3740 [==============================] - 17s 5ms/step - loss: 0.0524\n",
      "Epoch 4/10\n",
      "3740/3740 [==============================] - 18s 5ms/step - loss: 0.0478\n",
      "Epoch 5/10\n",
      "3740/3740 [==============================] - 18s 5ms/step - loss: 0.0436\n",
      "Epoch 6/10\n",
      "3740/3740 [==============================] - 18s 5ms/step - loss: 0.0405\n",
      "Epoch 7/10\n",
      "3740/3740 [==============================] - 16s 4ms/step - loss: 0.0387\n",
      "Epoch 8/10\n",
      "3740/3740 [==============================] - 17s 4ms/step - loss: 0.0352\n",
      "Epoch 9/10\n",
      "3740/3740 [==============================] - 17s 5ms/step - loss: 0.0337\n",
      "Epoch 10/10\n",
      "3740/3740 [==============================] - 16s 4ms/step - loss: 0.0331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2738f82e520>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndrop2.fit(X_train_cv_df, y_train, verbose = 1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:27:32.160817Z",
     "start_time": "2023-11-14T10:27:31.530162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130674554433108"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndrop2_test = nndrop2.predict(X_test_cv)\n",
    "nndrop2_test = nndrop2_test.round()\n",
    "accuracy_score(y_test, nndrop2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T10:28:01.857819Z",
     "start_time": "2023-11-14T10:28:01.840879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_3 (Dropout)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,346,950\n",
      "Trainable params: 1,346,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nndrop2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
